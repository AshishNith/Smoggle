# **Smoggle - Smart Glasses for the Visually Impaired** ğŸ‘“ğŸ™ï¸  

![Smoggle Banner](https://via.placeholder.com/1000x400?text=Smoggle+-+Smart+Glasses+for+Blind+People)  

**Smoggle** is an AI-powered smart glasses system designed to help visually impaired individuals navigate their surroundings independently. It uses an **ESP32-CAM** to capture images, sends them to an **LLM (GPT-4 Vision API) for analysis**, and provides real-time **in-ear audio feedback** using **text-to-speech (TTS)**.  

---

## ğŸŒŸ **Features**
âœ… **AI-Powered Object Recognition** â€“ Identifies objects, signs, and obstacles in the user's environment.  
âœ… **Text-to-Speech (TTS)** â€“ Converts AI-generated descriptions into speech for real-time guidance.  
âœ… **Lightweight & Portable** â€“ Designed to fit into a compact smart glasses frame.  
âœ… **Wi-Fi Connectivity** â€“ Sends images to a remote server for processing.  
âœ… **Easy to Use** â€“ Works automatically or via a button press.  

---

## ğŸš€ **How It Works**
1ï¸âƒ£ The **ESP32-CAM** captures an image of the environment.  
2ï¸âƒ£ The image is sent to a **Flask server**, which processes it using **GPT-4 Vision API**.  
3ï¸âƒ£ The AI analyzes the image and generates a description.  
4ï¸âƒ£ The description is converted into speech using **pyttsx3** (offline TTS).  
5ï¸âƒ£ The spoken response is played through an **earpiece or speaker**.  

---

## ğŸ›  **Technologies Used**
- **ESP32-CAM** â€“ For image capture  
- **Python (Flask)** â€“ Backend server  
- **OpenAI GPT-4 Vision API** â€“ For image analysis  
- **OpenCV & Ultralytics YOLO** â€“ For object detection  
- **Numpy** â€“ For image processing  
- **pyttsx3** â€“ For offline Text-to-Speech (TTS)  
- **Arduino IDE** â€“ For ESP32-CAM programming  

---

## ğŸ“‚ **Project Structure**
```
smoggle/
â”‚â”€â”€ esp32_code/        # ESP32-CAM firmware
â”‚   â”œâ”€â”€ smoggle.ino    
â”‚â”€â”€ server/            # Python backend
â”‚   â”œâ”€â”€ app.py       
â”‚â”€â”€ requirements.txt   # Python dependencies
â”‚â”€â”€ README.md          # Documentation
```

---

## ğŸ”§ **Installation & Setup**
### **1ï¸âƒ£ Setting Up ESP32-CAM**
1. Install **Arduino IDE** and add the **ESP32 board package**.  
2. Connect ESP32-CAM to your PC via **FTDI adapter**.  
3. Upload the `smoggle.ino` code from `esp32_code/`.  

### **2ï¸âƒ£ Installing Python Dependencies**
Before running the server, install the required Python libraries:  

#### **Installing dependencies from requirements.txt**
Run the following command in your terminal or command prompt:  
```bash
pip install -r requirements.txt
```

#### **Or install manually:**
```bash
pip install flask openai numpy opencv-python pyttsx3 ultralytics
```

### **3ï¸âƒ£ Setting Up the Server**
1. Replace `"your_openai_api_key"` in `app.py` with your OpenAI API key.  
2. Start the server:  
   ```bash
   python server/app.py
   ```

---

## ğŸ¯ **How to Use**
1ï¸âƒ£ **Power On** the ESP32-CAM module.  
2ï¸âƒ£ **Connect to Wi-Fi** (configured in `smoggle.ino`).  
3ï¸âƒ£ The glasses will automatically **capture images** and analyze the surroundings.  
4ï¸âƒ£ The system **speaks out** detected objects and text to assist the user.  

---

## ğŸ¯ **Future Improvements**
ğŸ”¹ Optimize AI processing for faster response times.  
ğŸ”¹ Implement **voice commands** for additional interaction.  
ğŸ”¹ Enhance **battery efficiency** for prolonged usage.  
ğŸ”¹ Add **edge AI** to reduce dependency on the internet.  

---

## ğŸ’¡ **Contributing**
We welcome contributions! Feel free to **fork the repository**, submit **pull requests**, or **open issues**.  

---

## ğŸ“œ **License**
This project is **open-source** and feel free to contribute.  

---

## âœ¨ **Team & Credits**
Developed by **Shirshak Mondal and Ashish Ranjan** and contributors ğŸš€  
Special thanks to **OpenAI**, **Ultralytics**, **OpenCV**, and the **ESP32 community** for their amazing tools!  

---

**Smoggle â€“ Empowering the Visually Impaired with AI** ğŸŒğŸ‘“âœ¨